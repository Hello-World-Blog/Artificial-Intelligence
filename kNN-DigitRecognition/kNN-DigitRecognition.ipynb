{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand written digit recognition using kNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset\n",
    "\n",
    "The dataset is a modified version of the “Optical Recognition of Handwritten Digits Data Set” by E. Alpaydin,\n",
    "C. Kaynak, Department of Computer Engineering at Bogazici University, 80815 Istanbul Turkey, retrieved\n",
    "from the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml) on October 3, 2010. You can get the dataset from here https://github.com/TarunNanduri/Artificial-Intelligence/kNN-DigitRecognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "kNN-DigitRecognition.ipynb\n",
      "testDigits\n",
      "trainingDigits\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "for name in listdir('./'):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0.txt\n",
      "0_1.txt\n",
      "0_10.txt\n",
      "0_100.txt\n",
      "0_101.txt\n"
     ]
    }
   ],
   "source": [
    "files = listdir('./trainingDigits')\n",
    "for i in range(0,5):\n",
    "    print(files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are of text format and each digit contains nearly 200 files\n",
    "\n",
    "# Let's check how the file looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000011100000000000000\n",
      "\n",
      "00000000000001111110000000000000\n",
      "\n",
      "00000000000011111111000000000000\n",
      "\n",
      "00000000000001111111100000000000\n",
      "\n",
      "00000000000011111111110000000000\n",
      "\n",
      "00000000000111111111110000000000\n",
      "\n",
      "00000001100111111001111000000000\n",
      "\n",
      "00000001111111110001111100000000\n",
      "\n",
      "00000011111111000000011100000000\n",
      "\n",
      "00000011111111000000011100000000\n",
      "\n",
      "00000011111111000000001100000000\n",
      "\n",
      "00000011111111000000000110000000\n",
      "\n",
      "00000011111111000000000110000000\n",
      "\n",
      "00000011111111000000000110000000\n",
      "\n",
      "00000011100110000000000110000000\n",
      "\n",
      "00000001110011000000000111000000\n",
      "\n",
      "00000001100000000000000111000000\n",
      "\n",
      "00000001110000000000000111000000\n",
      "\n",
      "00000000111000000000000111100000\n",
      "\n",
      "00000001111000000000000111000000\n",
      "\n",
      "00000001111000000000001111000000\n",
      "\n",
      "00000000111000000000011110000000\n",
      "\n",
      "00000000011100000000001111000000\n",
      "\n",
      "00000000011110000000011111000000\n",
      "\n",
      "00000000011111000000111100000000\n",
      "\n",
      "00000000001110000011111100000000\n",
      "\n",
      "00000000000111111111111100000000\n",
      "\n",
      "00000000000111111111111000000000\n",
      "\n",
      "00000000000111111111111000000000\n",
      "\n",
      "00000000000011111111110000000000\n",
      "\n",
      "00000000000000111111000000000000\n",
      "\n",
      "00000000000000011000000000000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digit = open(\"./trainingDigits/0_13.txt\", \"r\")\n",
    "for line in digit.readlines():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data\n",
    "\n",
    "The data is already split into \"testDigits\" and \"trainingDigits\".So, we need just need to make them suitable to build model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is in the form of 32x32 image.In order to train the model, we need to convert our 32x32 image into (1,1024) NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "\n",
    "def img2vector(filename):\n",
    "    imgVector = []\n",
    "    file = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = file.readline()\n",
    "        for j in range(32):\n",
    "            imgVector.append(int(lineStr[j]))\n",
    "    return imgVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = './trainingDigits'\n",
    "trainingFiles = listdir(trainData)\n",
    "trainDigits = []\n",
    "trainLabels = []\n",
    "for file in trainingFiles:\n",
    "    trainDigits.append(img2vector(trainData+'/'+file))\n",
    "    trainLabels.append(int(file[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our train data is ready. Now, let's make our test data ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = './testDigits'\n",
    "testingFiles = listdir(testData)\n",
    "testDigits = []\n",
    "testLabels = []\n",
    "for file in testingFiles:\n",
    "    testDigits.append(img2vector(testData+'/'+file))\n",
    "    testLabels.append(int(file[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the data is ready for building a model. So, let's start build our model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819027921406411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(trainDigits,trainLabels)\n",
    "trainScore = knn.score(trainDigits,trainLabels)\n",
    "\n",
    "print(trainScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whooohh! That was a great accuracy.Now let's see how our model behaves on unseen data.\n",
    "\n",
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(testDigits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "[[ 87   0   0   0   0   0   0   0   0   0]\n",
      " [  0  96   0   0   0   0   0   1   0   0]\n",
      " [  0   0  92   0   0   0   0   0   0   0]\n",
      " [  0   0   0  83   0   0   0   0   1   1]\n",
      " [  1   0   0   0 113   0   0   0   0   0]\n",
      " [  0   0   0   1   0 106   0   0   0   1]\n",
      " [  0   0   0   0   0   0  87   0   0   0]\n",
      " [  0   0   0   0   0   0   0  96   0   0]\n",
      " [  0   5   0   2   0   0   1   0  83   0]\n",
      " [  0   1   0   1   0   1   0   1   0  85]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        87\n",
      "           1       0.94      0.99      0.96        97\n",
      "           2       1.00      1.00      1.00        92\n",
      "           3       0.95      0.98      0.97        85\n",
      "           4       1.00      0.99      1.00       114\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        87\n",
      "           7       0.98      1.00      0.99        96\n",
      "           8       0.99      0.91      0.95        91\n",
      "           9       0.98      0.96      0.97        89\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       946\n",
      "   macro avg       0.98      0.98      0.98       946\n",
      "weighted avg       0.98      0.98      0.98       946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(testLabels,pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(testLabels,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9809725158562368"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(testLabels,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model has an accuracy of 0.98"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
